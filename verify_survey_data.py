# =============================================================================
# AG2 Report Verification Script
# --------
# This script verifies that the two survey reports generated by process_survey_data_1
# and process_survey_data_2 contain identical statistical results, regardless of
# differences in formatting, structure, or wording.
# =============================================================================

from dotenv import load_dotenv
import os
from autogen.agentchat.group import AgentTarget, ContextVariables, ReplyResult, TerminateTarget
from autogen import UserProxyAgent, ConversableAgent, LLMConfig, UpdateSystemMessage
from autogen.agentchat.group.patterns import DefaultPattern
from autogen.agentchat import initiate_group_chat
from pydantic import BaseModel, Field

# Load environment variables from .env file
load_dotenv()

def run_verification(model: str):
    """
    Executes the verification workflow to ensure that two survey reports
    contain identical statistical results.

    """

    print("Initiating the Report Verification Process...")

    # ---------------------------
    # LLM configuration
    # ---------------------------
    llm_config = LLMConfig(
        api_type="openai",
        model=model,
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0,  # Deterministic output for reproducibility
        cache_seed=None,
    )

    # ---------------------------
    # Shared context variables
    # ---------------------------
    shared_context = ContextVariables(data={
        "survey_report_1": "",
        "survey_report_2": "",
        "verified": False,   # Final verification result (True/False)
        "verification_feedback": "",  # Verification feedback

    })

    # ---------------------------
    # Tool: Read survey reports
    # ---------------------------
    def read_survey_reports(context_variables: ContextVariables) -> ReplyResult:
        """
        Reads both survey reports from disk and stores their content in shared context.

        """
        file_paths = {
            "survey_report_1": "Report 1/survey_results_run_1.md",
            "survey_report_2": "Report 2/survey_results_run_2.md",
        }

        for key, path in file_paths.items():
            with open(path, "r", encoding="utf-8") as f:
                context_variables[key] = f.read()

        return ReplyResult(
            message="Reports read successfully.",
            target=AgentTarget(verify_reports_agent),
            context_variables=context_variables,
        )

  
    # ---------------------------
    # Tool: Submit verification status
    # ---------------------------
    def submit_verification_status(verified: bool, feedback: str, context_variables: ContextVariables) -> ReplyResult:
        """
        Records the verification result in shared context and terminates the workflow.

        """
        context_variables["verified"] = verified
        context_variables["verification_feedback"] = feedback
        return ReplyResult(
            message=f"Verification status submitted successfully: verified={verified}",
            target=TerminateTarget(),
            context_variables=context_variables,
        )

    # ---------------------------
    # Agent definitions
    # ---------------------------
    with llm_config:
        # Agent that reads both reports
        read_reports_agent = ConversableAgent(
            name="read_reports_agent",
            system_message="""You are the agent that reads the survey reports.
            Your task is to read the survey reports and store them in the shared context.

            Use the read_survey_reports tool to read the survey reports.""",
            functions=[read_survey_reports]
        )

        # Agent that verifies statistical consistency
        verify_reports_agent = ConversableAgent(
            name="verify_reports_agent",
            system_message="""You are the agent responsible for verifying the consistency of two survey reports.""",
            functions=[submit_verification_status],
            update_agent_state_before_reply=[
                UpdateSystemMessage(
                    """
                    ROLE:
                    You are the agent responsible for verifying the consistency of two survey reports.
                    Your task is to examine 'survey_report_1' and 'survey_report_2' and verify that they are consistent.
                    
                    INPUTS:
                    • survey report 1: {survey_report_1}
                    • survey report 2: {survey_report_2}

                    TOOLS:
                    • submit_verification_status(verified: bool, feedback: str) - Submit the verification result and feedback.

                    WORKFLOW:
                    1. Read both survey reports.
                    2. Verify that the statistical results are consistent across both reports.
                       
                       These reports may differ in structure, wording, or formatting — that is acceptable. However, the **statistical results** 
                       (such as percentages, counts, means, etc.) must be the same in both reports.

                       Compare the statistics presented in each report. If all the statistics are consistent across both reports, 
                       verification shall be considered successful (TRUE). If there are any discrepancies in the statistics — regardless 
                       of formatting or phrasing — verification shall be considered unsuccessful (FALSE).

                       If verification is unsuccessful, provide a detailed explanation of the discrepancies in your feedback.

                       If verification is successful, explain that you have confirmed and verified the consistency of the reports in your feedback.

                    SUBMISSION:
                    You MUST use the submit_verification_status function to record the verification result and feedback.

                    After the verification result and feedback have been submitted, reply with 'TERMINATE'.

                    """
                )
            ]
        )

    # ---------------------------
    # User agent
    # ---------------------------
    user = UserProxyAgent(
        name="user",
        code_execution_config=False
    )

    # Define workflow handoffs
    read_reports_agent.handoffs.set_after_work(AgentTarget(verify_reports_agent))
    verify_reports_agent.handoffs.set_after_work(TerminateTarget())

    # ---------------------------
    # Orchestration pattern
    # ---------------------------
    agent_pattern = DefaultPattern(
        initial_agent=read_reports_agent,
        agents=[
            read_reports_agent,
            verify_reports_agent,
        ],
        context_variables=shared_context,
        user_agent=user,
        group_manager_args={
            "llm_config": llm_config,
            # Stop when the agent returns exactly "TERMINATE"
            "is_termination_msg": lambda msg: msg.get("content", "").strip() == "TERMINATE"
        }
    )

    # ---------------------------
    # Run verification process
    # ---------------------------
    chat_result, final_context, last_agent = initiate_group_chat(
        pattern=agent_pattern,
        messages="Verify the consistency of the statistics in the two survey reports.",
        max_rounds=20,
    )

    # ---------------------------
    # Output verification result
    # ---------------------------
    if final_context.get("verified"):
        print("Report verification completed successfully!")
        print("Verification Feedback:", final_context.get("verification_feedback"))
    else:
        print("Report verification did not complete successfully.")
        print("Verification Feedback:", final_context.get("verification_feedback"))

